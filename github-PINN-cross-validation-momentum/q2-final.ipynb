{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c98cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries  \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "# True parameters\n",
    "gamma_true = 0.1\n",
    "omega_true = 1.0\n",
    "\n",
    "def damped_oscillator(t, y, gamma, omega):\n",
    "    x, x_dot = y\n",
    "    x_ddot = -2*gamma*x_dot - omega**2*x\n",
    "    return np.array([x_dot, x_ddot])\n",
    "\n",
    "# Initial conditions\n",
    "x0 = 1.0\n",
    "xdot0 = 0.0\n",
    "y0 = np.array([x0, xdot0])\n",
    "\n",
    "# Time domain\n",
    "t_span = (0, 10)\n",
    "t_eval = np.linspace(0, 10, 100)\n",
    "\n",
    "# Solve the ODE\n",
    "sol = solve_ivp(damped_oscillator, t_span, y0, args=(gamma_true, omega_true), \n",
    "                t_eval=t_eval, method='RK45', rtol=1e-8)\n",
    "\n",
    "# Extract solution\n",
    "t_data = sol.t\n",
    "x_data = sol.y[0]\n",
    "\n",
    "# Plot ground truth\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(t_data, x_data, 'b-', linewidth=2, label='Ground truth')\n",
    "plt.xlabel('Time t')\n",
    "plt.ylabel('x(t)')\n",
    "plt.title('Ground Truth: Damped Oscillator')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Generated {len(t_data)} data points\")\n",
    "# Define fully-connected neural network\n",
    "class FCN(nn.Module):\n",
    "    \n",
    "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
    "        super().__init__()\n",
    "        activation = nn.Tanh\n",
    "        self.fcs = nn.Sequential(*[\n",
    "                        nn.Linear(N_INPUT, N_HIDDEN),\n",
    "                        activation()])\n",
    "        self.fch = nn.Sequential(*[\n",
    "                        nn.Sequential(*[\n",
    "                            nn.Linear(N_HIDDEN, N_HIDDEN),\n",
    "                            activation()]) for _ in range(N_LAYERS-1)])\n",
    "        self.fce = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fcs(x)\n",
    "        x = self.fch(x)\n",
    "        x = self.fce(x)\n",
    "        return x\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define neural network\n",
    "pinn = FCN(1, 1, 32, 3)  # Input: t, Output: x(t), Hidden: 32 nodes, 3 layers\n",
    "\n",
    "# Define trainable parameters gamma and omega\n",
    "gamma = torch.nn.Parameter(torch.tensor([0.5], requires_grad=True))  # Initial guess\n",
    "omega = torch.nn.Parameter(torch.tensor([0.5], requires_grad=True))  # Initial guess\n",
    "\n",
    "print(\"PINN Architecture:\")\n",
    "print(pinn)\n",
    "print(f\"\\nTrainable parameters:\")\n",
    "print(f\"  - gamma (initial): {gamma.item():.4f}\")\n",
    "print(f\"  - omega (initial): {omega.item():.4f}\")\n",
    "\n",
    "# Prepare training data\n",
    "# Number of data points to use for training \n",
    "n_data = 20  # Use 20 data points\n",
    "data_indices = np.linspace(0, len(t_data)-1, n_data, dtype=int)\n",
    "t_data_train = torch.tensor(t_data[data_indices], dtype=torch.float32).view(-1, 1)\n",
    "x_data_train = torch.tensor(x_data[data_indices], dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Number of collocation points for physics loss\n",
    "n_collocation = 100\n",
    "t_physics = torch.linspace(0, 10, n_collocation).view(-1, 1).requires_grad_(True)\n",
    "\n",
    "# Initial condition points\n",
    "t_ic = torch.tensor([[0.0]], requires_grad=True)\n",
    "\n",
    "# Test points for evaluation\n",
    "t_test = torch.linspace(0, 10, 200).view(-1, 1)\n",
    "\n",
    "print(f\"Training setup:\")\n",
    "print(f\"  - Number of data points: {n_data}\")\n",
    "print(f\"  - Number of collocation points: {n_collocation}\")\n",
    "print(f\"  - Time domain: [0, 10]\")\n",
    "\n",
    "# Setup optimizer (include PINN parameters and trainable gamma, omega)\n",
    "optimizer = torch.optim.Adam(list(pinn.parameters()) + [gamma, omega], lr=1e-3)\n",
    "\n",
    "# Hyperparameters for loss weighting\n",
    "lambda_data = 1.0      # Weight for data loss\n",
    "lambda_physics = 1e-4  # Weight for physics loss\n",
    "lambda_ic = 1.0        # Weight for initial conditions\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 20000\n",
    "loss_history = []\n",
    "gamma_history = []\n",
    "omega_history = []\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 1. Data loss: MSE between PINN prediction and observed data\n",
    "    x_pred_data = pinn(t_data_train)\n",
    "    loss_data = torch.mean((x_pred_data - x_data_train)**2)\n",
    "    \n",
    "    # 2. Physics loss: Residual of the ODE on collocation points\n",
    "    x_pred_physics = pinn(t_physics)\n",
    "    x_t = torch.autograd.grad(x_pred_physics, t_physics, \n",
    "                              torch.ones_like(x_pred_physics), \n",
    "                              create_graph=True)[0]\n",
    "    x_tt = torch.autograd.grad(x_t, t_physics, \n",
    "                               torch.ones_like(x_t), \n",
    "                               create_graph=True)[0]\n",
    "    \n",
    "    # ODE residual: x'' + 2*gamma*x' + omega^2*x = 0\n",
    "    residual = x_tt + 2*gamma*x_t + omega**2*x_pred_physics\n",
    "    loss_physics = torch.mean(residual**2)\n",
    "    \n",
    "    # 3. Initial condition loss\n",
    "    x_ic = pinn(t_ic)\n",
    "    x_ic_t = torch.autograd.grad(x_ic, t_ic, \n",
    "                                  torch.ones_like(x_ic), \n",
    "                                  create_graph=True)[0]\n",
    "    loss_ic_x = (x_ic - 1.0)**2  # x(0) = 1\n",
    "    loss_ic_xdot = (x_ic_t - 0.0)**2  # x'(0) = 0\n",
    "    loss_ic = loss_ic_x + loss_ic_xdot\n",
    "    \n",
    "    # Total loss\n",
    "    loss = lambda_data*loss_data + lambda_physics*loss_physics + lambda_ic*loss_ic\n",
    "    \n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Record history\n",
    "    loss_history.append(loss.item())\n",
    "    gamma_history.append(gamma.item())\n",
    "    omega_history.append(omega.item())\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 2000 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} | Loss: {loss.item():.6f} | \"\n",
    "              f\"γ: {gamma.item():.4f} | ω: {omega.item():.4f}\")\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print(f\"Final γ: {gamma.item():.6f} (true: {gamma_true})\")\n",
    "print(f\"Final ω: {omega.item():.6f} (true: {omega_true})\")\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Plot 1: Total loss\n",
    "axes[0].plot(loss_history, 'b-', linewidth=1)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Total Loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Gamma convergence\n",
    "axes[1].plot(gamma_history, 'r-', linewidth=1, label='PINN estimate')\n",
    "axes[1].axhline(y=gamma_true, color='g', linestyle='--', linewidth=2, label='True value')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('γ')\n",
    "axes[1].set_title('Convergence of γ')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Omega convergence\n",
    "axes[2].plot(omega_history, 'r-', linewidth=1, label='PINN estimate')\n",
    "axes[2].axhline(y=omega_true, color='g', linestyle='--', linewidth=2, label='True value')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('ω')\n",
    "axes[2].set_title('Convergence of ω')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Generate predictions\n",
    "with torch.no_grad():\n",
    "    x_pred = pinn(t_test).numpy()\n",
    "\n",
    "# Compute errors\n",
    "gamma_error = abs(gamma.item() - gamma_true)\n",
    "omega_error = abs(omega.item() - omega_true)\n",
    "gamma_rel_error = 100 * gamma_error / gamma_true\n",
    "omega_rel_error = 100 * omega_error / omega_true\n",
    "\n",
    "# Compute solution error (MSE on full ground truth)\n",
    "t_full = torch.tensor(t_data, dtype=torch.float32).view(-1, 1)\n",
    "with torch.no_grad():\n",
    "    x_pred_full = pinn(t_full).numpy()\n",
    "x_true_full = x_data\n",
    "mse_solution = np.mean((x_pred_full.flatten() - x_true_full)**2)\n",
    "rmse_solution = np.sqrt(mse_solution)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nParameter Recovery:\")\n",
    "print(f\"  γ (gamma):\")\n",
    "print(f\"    True value:      {gamma_true:.6f}\")\n",
    "print(f\"    PINN estimate:   {gamma.item():.6f}\")\n",
    "print(f\"    Absolute error:  {gamma_error:.6f}\")\n",
    "print(f\"    Relative error:  {gamma_rel_error:.2f}%\")\n",
    "print(f\"\\n  ω (omega):\")\n",
    "print(f\"    True value:      {omega_true:.6f}\")\n",
    "print(f\"    PINN estimate:   {omega.item():.6f}\")\n",
    "print(f\"    Absolute error:  {omega_error:.6f}\")\n",
    "print(f\"    Relative error:  {omega_rel_error:.2f}%\")\n",
    "\n",
    "print(f\"\\nSolution Accuracy:\")\n",
    "print(f\"  RMSE on full domain: {rmse_solution:.6f}\")\n",
    "print(f\"  MSE on full domain:  {mse_solution:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DISCUSSION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nDiscrepancies:\")\n",
    "if gamma_rel_error < 5 and omega_rel_error < 5:\n",
    "    print(\"  - Both parameters recovered with excellent accuracy (<5% error)\")\n",
    "elif gamma_rel_error < 10 and omega_rel_error < 10:\n",
    "    print(\"  - Both parameters recovered with good accuracy (<10% error)\")\n",
    "else:\n",
    "    print(\"  - Some discrepancies observed in parameter recovery\")\n",
    "\n",
    "if gamma_rel_error > omega_rel_error:\n",
    "    print(f\"  - γ has larger relative error ({gamma_rel_error:.2f}%) than ω\")\n",
    "else:\n",
    "    print(f\"  - ω has larger relative error ({omega_rel_error:.2f}%) than γ\")\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(t_data, x_data, 'b-', linewidth=3, label='Ground truth', alpha=0.7)\n",
    "plt.plot(t_test.numpy(), x_pred, 'r--', linewidth=2, label='PINN prediction')\n",
    "plt.scatter(t_data_train.numpy(), x_data_train.numpy(), \n",
    "            c='green', s=80, zorder=5, marker='o', \n",
    "            edgecolors='darkgreen', linewidth=1.5,\n",
    "            label=f'Training data (n={n_data})', alpha=0.8)\n",
    "plt.xlabel('Time t', fontsize=13)\n",
    "plt.ylabel('x(t)', fontsize=13)\n",
    "plt.title(f'PINN Solution: γ={gamma.item():.4f} (true: {gamma_true}), ω={omega.item():.4f} (true: {omega_true})', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11, loc='upper right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(0, 10)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
